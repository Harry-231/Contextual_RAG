{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9f56d0",
   "metadata": {},
   "source": [
    "# Creating a RAG with Langchain , Voyage AI Embeddings and OpenAI , Atlas VectorStore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0418e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"VOYAGE_API_KEY\"] = os.getenv(\"VOYAGE_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = 'true'\n",
    "os.environ[\"MONGODB_URI\"] = os.getenv(\"MONGODB_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "064f6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pymongo, pprint\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import SearchIndexModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e118da86",
   "metadata": {},
   "source": [
    "## Step 1: (INGESTION) Loading the documents and processing to get ready for embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd676ae",
   "metadata": {},
   "source": [
    "## Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfa324",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = (\"your_pdf_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d704fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path=pdf_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e83b31",
   "metadata": {},
   "source": [
    "## Chunking the data using the Semantic chunker from Langchain for better context retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1e1f792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "embeddings = VoyageAIEmbeddings(model = \"voyage-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "767a7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "text_splitter = SemanticChunker(embeddings=embeddings,breakpoint_threshold_type=\"gradient\",min_chunk_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "300523eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0,len(pages)):\n",
    "    documents.append(text_splitter.create_documents([pages[idx].page_content]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[doc.page_content for doc in doc_group] for doc_group in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef97b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceacc6f",
   "metadata": {},
   "source": [
    "## Creating Vector Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "model = 'voyage-context-3'\n",
    "vo = voyageai.Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3304a",
   "metadata": {},
   "source": [
    "### Custom VoyageAIEmbedding wrapper for 'voyage-context-3' model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "87449842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Callable, Any\n",
    "import voyageai\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, root_validator\n",
    "\n",
    "\n",
    "class VoyageAIEmbedding(BaseModel, Embeddings):\n",
    "    \"\"\"\n",
    "    VoyageAI embeddings using contextualized_embed method.\n",
    "    \n",
    "    This class provides a LangChain-compatible interface for VoyageAI's\n",
    "    contextualized embedding functionality.\n",
    "    \"\"\"\n",
    "    \n",
    "    client: Any = Field(default=None, exclude=True)\n",
    "    model: str = Field(default=\"voyage-context-3\")\n",
    "    voyage_api_key: Optional[str] = Field(default=None, alias=\"api_key\")\n",
    "    input_type: str = Field(default=\"document\")\n",
    "    output_dimension: Optional[int] = Field(default=None)\n",
    "    output_dtype: str = Field(default=\"float\")\n",
    "    chunk_fn: Optional[Callable[[str], List[str]]] = Field(default=None)\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "        extra = \"forbid\"\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: dict) -> dict:\n",
    "        \"\"\"Validate that api key exists in environment.\"\"\"\n",
    "        \n",
    "        # Initialize the VoyageAI client\n",
    "        api_key = values.get(\"voyage_api_key\")\n",
    "        if api_key:\n",
    "            values[\"client\"] = voyageai.Client(api_key=api_key)\n",
    "        else:\n",
    "            \n",
    "            values[\"client\"] = voyageai.Client()\n",
    "        \n",
    "        return values\n",
    "\n",
    "    def embed_documents(self, texts) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Embed search docs using VoyageAI's contextualized_embed method.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of document strings or Document objects to embed\n",
    "            \n",
    "        Returns:\n",
    "            List of embeddings, one for each document\n",
    "        \"\"\"\n",
    "        if not texts:\n",
    "            return []\n",
    "        \n",
    "        # Handle case where Document objects are passed instead of strings\n",
    "        processed_texts = []\n",
    "        for text in texts:\n",
    "            if hasattr(text, 'page_content'):\n",
    "                # It's a Document object\n",
    "                processed_texts.append(text.page_content)\n",
    "            elif isinstance(text, str):\n",
    "                # It's already a string\n",
    "                processed_texts.append(text)\n",
    "            else:\n",
    "                # Convert to string as fallback\n",
    "                processed_texts.append(str(text))\n",
    "        \n",
    "        # Filter out empty strings\n",
    "        processed_texts = [text.strip() for text in processed_texts if text and text.strip()]\n",
    "        \n",
    "        if not processed_texts:\n",
    "            return []\n",
    "        \n",
    "        \n",
    "        inputs = [[text] for text in processed_texts]\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            result = self.client.contextualized_embed(\n",
    "                inputs=inputs,\n",
    "                model=self.model,\n",
    "                input_type=self.input_type,\n",
    "                output_dimension=self.output_dimension,\n",
    "                output_dtype=self.output_dtype,\n",
    "            )\n",
    "            \n",
    "            # Extract embeddings from the result\n",
    "            # The result structure might vary, so we need to handle it properly\n",
    "            if hasattr(result, 'results') and result.results:\n",
    "                # If results is a list, get the first element\n",
    "                embed_obj = result.results[0]\n",
    "                if hasattr(embed_obj, 'embeddings'):\n",
    "                    return embed_obj.embeddings\n",
    "                elif hasattr(embed_obj, 'embedding'):\n",
    "                    return embed_obj.embedding\n",
    "                else:\n",
    "                    return embed_obj\n",
    "            elif hasattr(result, 'embeddings'):\n",
    "                return result.embeddings\n",
    "            else:\n",
    "                return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error calling VoyageAI contextualized_embed: {e}\")\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Embed query text using VoyageAI's contextualized_embed method.\n",
    "        \n",
    "        Args:\n",
    "            text: Query text to embed\n",
    "            \n",
    "        Returns:\n",
    "            Embedding for the query\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            query_input_type = \"query\" if self.input_type == \"document\" else self.input_type\n",
    "            \n",
    "            result = self.client.contextualized_embed(\n",
    "                inputs=[[text]], \n",
    "                model=self.model,\n",
    "                input_type=query_input_type,\n",
    "                output_dimension=self.output_dimension,\n",
    "                output_dtype=self.output_dtype,\n",
    "                chunk_fn=self.chunk_fn\n",
    "            )\n",
    "            \n",
    "            \n",
    "            if hasattr(result, 'results') and result.results:\n",
    "                embed_obj = result.results[0]\n",
    "                if hasattr(embed_obj, 'embeddings'):\n",
    "                    return embed_obj.embeddings[0] if embed_obj.embeddings else []\n",
    "                elif hasattr(embed_obj, 'embedding'):\n",
    "                    return embed_obj.embedding[0] if embed_obj.embedding else []\n",
    "                else:\n",
    "                    return embed_obj[0] if embed_obj else []\n",
    "            elif hasattr(result, 'embeddings'):\n",
    "                return result.embeddings[0] if result.embeddings else []\n",
    "            else:\n",
    "                return result[0] if result else []\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error calling VoyageAI contextualized_embed for query: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a472b0",
   "metadata": {},
   "source": [
    "## Defining the vectorstore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from langchain_mongodb.vectorstores import MongoDBAtlasVectorSearch\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "DB_NAME = \"Voyage_ai_RAG\"\n",
    "COLLECTION_NAME = \"langhcain_Voyage\"\n",
    "clinet = MongoClient()\n",
    "vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    connection_string=os.getenv(\"MONGODB_URI\"),\n",
    "    namespace=f\"{DB_NAME}.{COLLECTION_NAME}\",\n",
    "    embedding=VoyageAIEmbedding(model=\"voyage-context-3\"),\n",
    "    index_name=\"vector_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "465f514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0 with 3 documents\n",
      "✓ Successfully added batch 0\n",
      "Processing batch 1 with 3 documents\n",
      "✓ Successfully added batch 1\n",
      "Processing batch 2 with 3 documents\n",
      "✓ Successfully added batch 2\n",
      "Processing batch 3 with 3 documents\n",
      "✓ Successfully added batch 3\n",
      "Processing batch 4 with 3 documents\n",
      "✓ Successfully added batch 4\n",
      "Processing batch 5 with 3 documents\n",
      "✓ Successfully added batch 5\n",
      "Processing batch 6 with 3 documents\n",
      "✓ Successfully added batch 6\n",
      "Processing batch 7 with 3 documents\n",
      "✓ Successfully added batch 7\n",
      "Processing batch 8 with 4 documents\n",
      "✓ Successfully added batch 8\n",
      "Processing batch 9 with 3 documents\n",
      "✓ Successfully added batch 9\n",
      "Processing batch 10 with 3 documents\n",
      "✓ Successfully added batch 10\n",
      "Processing batch 11 with 3 documents\n",
      "✓ Successfully added batch 11\n",
      "Processing batch 12 with 2 documents\n",
      "✓ Successfully added batch 12\n",
      "Processing batch 13 with 3 documents\n",
      "✓ Successfully added batch 13\n",
      "Processing batch 14 with 3 documents\n",
      "✓ Successfully added batch 14\n",
      "Processing batch 15 with 3 documents\n",
      "✓ Successfully added batch 15\n",
      "Processing batch 16 with 3 documents\n",
      "✓ Successfully added batch 16\n",
      "Processing batch 17 with 3 documents\n",
      "✓ Successfully added batch 17\n",
      "Processing batch 18 with 2 documents\n",
      "✓ Successfully added batch 18\n",
      "Processing batch 19 with 2 documents\n",
      "✓ Successfully added batch 19\n",
      "Processing batch 20 with 5 documents\n",
      "✓ Successfully added batch 20\n",
      "Processing batch 21 with 2 documents\n",
      "✓ Successfully added batch 21\n",
      "Processing batch 22 with 2 documents\n",
      "✓ Successfully added batch 22\n",
      "Processing batch 23 with 4 documents\n",
      "✓ Successfully added batch 23\n",
      "Processing batch 24 with 4 documents\n",
      "✓ Successfully added batch 24\n",
      "Processing batch 25 with 2 documents\n",
      "✓ Successfully added batch 25\n",
      "Processing batch 26 with 2 documents\n",
      "✓ Successfully added batch 26\n",
      "Processing batch 27 with 3 documents\n",
      "✓ Successfully added batch 27\n",
      "Processing batch 28 with 3 documents\n",
      "✓ Successfully added batch 28\n",
      "Processing batch 29 with 2 documents\n",
      "✓ Successfully added batch 29\n",
      "Processing batch 30 with 4 documents\n",
      "✓ Successfully added batch 30\n",
      "Processing batch 31 with 3 documents\n",
      "✓ Successfully added batch 31\n",
      "Processing batch 32 with 4 documents\n",
      "✓ Successfully added batch 32\n",
      "Processing batch 33 with 4 documents\n",
      "✓ Successfully added batch 33\n",
      "Processing batch 34 with 4 documents\n",
      "✓ Successfully added batch 34\n",
      "Processing batch 35 with 3 documents\n",
      "✓ Successfully added batch 35\n",
      "Processing batch 36 with 3 documents\n",
      "✓ Successfully added batch 36\n",
      "Processing batch 37 with 4 documents\n",
      "✓ Successfully added batch 37\n",
      "Processing batch 38 with 3 documents\n",
      "✓ Successfully added batch 38\n",
      "Processing batch 39 with 3 documents\n",
      "✓ Successfully added batch 39\n",
      "Processing batch 40 with 3 documents\n",
      "✓ Successfully added batch 40\n",
      "Processing batch 41 with 2 documents\n",
      "✓ Successfully added batch 41\n",
      "Processing batch 42 with 2 documents\n",
      "✓ Successfully added batch 42\n",
      "Processing batch 43 with 2 documents\n",
      "✓ Successfully added batch 43\n",
      "Processing batch 44 with 2 documents\n",
      "✓ Successfully added batch 44\n",
      "Processing batch 45 with 2 documents\n",
      "✓ Successfully added batch 45\n",
      "Processing batch 46 with 2 documents\n",
      "✓ Successfully added batch 46\n",
      "Processing batch 47 with 2 documents\n",
      "✓ Successfully added batch 47\n",
      "Processing batch 48 with 2 documents\n",
      "✓ Successfully added batch 48\n"
     ]
    }
   ],
   "source": [
    "# Create a new embedding instance with the updated code\n",
    "\n",
    "\n",
    "# Now try adding documents to the vector store\n",
    "for idx in range(len(documents)):\n",
    "    try:\n",
    "        docs_batch = documents[idx]\n",
    "        print(f\"Processing batch {idx} with {len(docs_batch)} documents\")\n",
    "        vector_store.add_documents(documents=docs_batch)\n",
    "        print(f\"✓ Successfully added batch {idx}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error adding batch {idx}: {e}\")\n",
    "        break  # Stop on first error to see what's happening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538c353",
   "metadata": {},
   "source": [
    "# Step2 : Retrieval "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928146a4",
   "metadata": {},
   "source": [
    "## Performing Semantic Search on vector store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9138fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.create_vector_search_index(\n",
    "    dimensions = 1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "query = \"Your_query.\"\n",
    "\n",
    "\n",
    "result = vector_store.similarity_search(query)\n",
    "\n",
    "pprint.pprint(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025d7e8",
   "metadata": {},
   "source": [
    "# Step3 : Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da993dfb",
   "metadata": {},
   "source": [
    "## Making the final RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f47a89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs = {\"k\" : 5}\n",
    ")\n",
    "\n",
    "# Defining a prompt template\n",
    "\n",
    "template = \"\"\"\n",
    "   Use the following pieces of context to answer the question at the end.\n",
    "   {context}\n",
    "   Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "# Construct a chain to answer questions on your data\n",
    "chain = (\n",
    "   { \"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "   | prompt\n",
    "   | model\n",
    "   | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the chain\n",
    "question = \"your_query\"\n",
    "answer = chain.invoke(question)\n",
    "print(\"Question: \" + question)\n",
    "print(\"Answer: \" + answer)\n",
    "# Return source documents\n",
    "documents = retriever.invoke(question)\n",
    "print(\"\\nSource documents:\")\n",
    "pprint.pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a16c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
